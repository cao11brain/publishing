모델링
Linear Regression 
- cost function 으로 최적의 모델을 구함 
- cost function = (실제값-예측값)^2 / N = MSE(Mean Square Error) 
##### 지도학습
분류모델(Classification)
- 비연속적인 값으로 되어 있을 경우 
예측모델(Regression, 회귀모델) 
- 연속적인 값으로 되어 있을 경우
Confusion Matrix 
- TP(True Positive) : True 를 True 로 예측함 (앞에는 맞췄냐 틀렸냐, 뒤는 어떤 값으로 예측했냐)
- FN(False Negative) : True 를 False 로 예측함 
성능지표 
- 정밀도(Precision) = TP / (TP+FP) , True 라고 예측한 것 중에서 맞춘 것의 갯수 
- 재현율(Recall) = TP / (TP+FN) , 실제 True 인 것 중에서 모델에서도 True 로 예측한 비율
- 정확도(Accuracy)
- F1-score
##### 알고리즘
머신러닝 패키지 : scikit-learn 패키지에 대부분 내장 
##### Linear Regression 
`from sklearn.family import Model` 의 형태로.. 예를 들면
	`from sklearn.linear_model import LinearRegression`
	`model=LinearRegression()`
==모델링 방법.. 아주 쉽다 - 4단계면 끝난다. 모델 불러오고 저장한뒤 학습, 검증 순서==
	`from sklearn.linear_model import LinearRegression`
	`model=LinearRegression()`
	`model.fit(X_train, y_train)
	`pred=model.predict(X_test)`
##### K-Nearest Neighbor
코딩 예시
	`from sklearn.neighbors import KNeiborsClassifier
	`knn = KNeighborsClassifier(n+neighbors=3)`
	`knn.fit(X_train, y_train)`
	`pred = knn.predict(X_test)
##### Random Forest (앙상블 기법, 여러개 모델을 섞어서)
코딩 예시
	`from sklearn.ensemble import RandomForestClassifire`
	`model=RandomForestClassifier(n_estimators=50)`
	`model.fit(X_train, y_train)`
	`pred=model.predict(X_test)`
적절한 하이퍼 파라미터 튜닝이 중요함 
##### 앙상블 기법이란?? 
###### Boosting 
순차적 학습을 하면서 잘못된 예측에 weight 를 부여해서 오차를 보완해나감
순차적 학습 = Sequantial (<=> parallel 방식, RandomForest)
모델 : XGBoost, LightGBM 
	`!pip install xgboost
	`from xgboost import XGBClassifier
	`model=XGBClassifier(n_estimator=50)
	`model=fit(X_train, y_train)
	`pred=model.predict(X_test)
###### Bagging 
###### Stacking 
여러개 모델이 예측한 결과 데이터를 가지고 다시 final_estimator 모델로 종합해 예측함
	`from sklearn.ensemble import StackingRegressor, StackingClassifier
	`stack_model = [ (‘LogisticRegression’, lg), …, ]
	`stacking = StackingClassifier(stack_models, final_estimator=rft, n_jobs=1)`
- final_estimator 로 마지막으로 예측을 하게 됨 
###### Weighted Blending 
모델의 예측값에 대해 weigh 를 곱해서 최종 output 을 계산함 

##### 데이터셋 분할 
`from sklearn.model_selection import train_test_split`
`x = df1.drop(‘termination_Y’, axis=1).values
`y = df1[‘termination_Y’].values
`X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, rando_state=42)`
- stratify = ‘Name’ 어떤 데이터 값에 대해서 동일한 비율로 나누라는 뜻 
###### 데이터 정규화(Normaizing/Scailing) 
`from sklearn.preprocessing import MinMaxScaler
`scaler=MinMaxScaler() 
`X_train = scaler.fit_transform(X_train)
`X_test = scaler.transform(X_test)